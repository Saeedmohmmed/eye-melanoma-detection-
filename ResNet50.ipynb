{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ResNet50.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlmw7qBheXWc"
      },
      "source": [
        "!gdown --id 1zoJp9Z19qRflaTiZ3Osnj6EXI_9YK_O1\n",
        "\n",
        "\n",
        "#1-5iThilGeWEc00S3WOyGgupYwJS0EsbN        data without any thing hhhhhhhhh\n",
        "\n",
        "#https://drive.google.com/file/d/1zoJp9Z19qRflaTiZ3Osnj6EXI_9YK_O1/view?usp=sharing   Aug_data & preprocessing\n",
        "\n",
        "#https://drive.google.com/file/d/1U5WvGLhki5Tjot8O7hGCoWOzJQiEt6oa/view?usp=sharing      TTV2_Aug_data\n",
        "\n",
        "#https://drive.google.com/file/d/1QaSpkDcwcV4wfEUwDOdbcr-BpDgQGEJu/view?usp=sharing      TTV_Aug_data\n",
        "\n",
        "#https://drive.google.com/file/d/1lgLRU4jGo9PryAJ7hruVMO5FgaLIh9Hr/view?usp=sharing      1lgLRU4jGo9PryAJ7hruVMO5FgaLIh9Hr      Aug_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zppg9KXWenmo"
      },
      "source": [
        "#unzip folder\n",
        "#!unzip All_resized_data.zip\n",
        "\n",
        "!unrar x Preprocessed_Dataset.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXORLuMwqqQd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THaT8g7qennv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data science tools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Image manipulations\n",
        "from PIL import Image\n",
        "# Useful for examining network\n",
        "from torchsummary import summary\n",
        "# Timing utility\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['font.size'] = 14\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq0fi-RfensK"
      },
      "source": [
        "base_dir = '/content/Preprocessed_Dataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_melanoma_dir = os.path.join(train_dir, 'melanoma')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_not_melanoma_dir = os.path.join(train_dir, 'not_melanoma')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_melanoma_dir = os.path.join(validation_dir, 'melanoma')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_not_melanoma_dir = os.path.join(validation_dir, 'not_melanoma')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "test_melanoma_dir = os.path.join(test_dir, 'melanoma')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "test_not_melanoma_dir = os.path.join(test_dir, 'not_melanoma')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx6jVpWRens3"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "validation_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Note that the test data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvEXukm7enxl"
      },
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
        "\n",
        "\n",
        "# Flow validation images in batches of 20 using validation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir,  batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,  batch_size = 20, class_mode = 'binary', target_size = (224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arN5a-XJen24"
      },
      "source": [
        "import os \n",
        "import zipfile \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Model \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl1fo8UWenyP"
      },
      "source": [
        "#  Recall()\n",
        "#  Precision()\n",
        "presc = tf.keras.metrics.Precision(name='precision')\n",
        "recall = tf.keras.metrics.Recall(name='recall')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTSV_DaWen3m"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "base_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsZESZZFen8R"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxIvOuhv1TZN"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "optimizer = Adam(lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xN4ns2Qen89"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        " \n",
        "base_model = Sequential()\n",
        "base_model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
        "base_model.add(Dense(512, activation='relu'))\n",
        "base_model.add(Dropout(0.3))\n",
        "base_model.add(Dense(256, activation='relu'))\n",
        "base_model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xeRzlYA1Cr7"
      },
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "tz_NY = pytz.timezone('Africa/Cairo') \n",
        "current_time = datetime.now(tz_NY).strftime(\"%H-%M-%S\")\n",
        "file_name = 'ResNet50_finetune-'+current_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG8PaFBxiudL"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=10, verbose=1, mode='min', min_lr=5e-5)\n",
        "checkpoint = ModelCheckpoint(file_name, monitor= 'val_loss', mode= 'min', save_best_only = True, verbose= 1)\n",
        "\n",
        "callbacks=[lr_reduce,checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHjzFBrHfpvP"
      },
      "source": [
        "base_model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['acc', recall, presc])\n",
        "#tf.keras.optimizers.SGD(lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13WZUfv2gYFW"
      },
      "source": [
        "steps_per_epoch = 2585//20 #20 for batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFh5eomMfpzV"
      },
      "source": [
        "resnet_history = base_model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = steps_per_epoch, epochs = 60, callbacks=callbacks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtZTigRksuzs"
      },
      "source": [
        "plt.figure(figsize=[8,6])\n",
        "# x = 1000\n",
        "plt.axis([0, 60, 0, 5])\n",
        "plt.plot(resnet_history.history['loss'],'r',linewidth=3.0)\n",
        "\n",
        "plt.plot(resnet_history.history['val_loss'],'b',linewidth=3.0)\n",
        "\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "\n",
        "plt.title('Loss Curves',fontsize=16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy0HP-V5svF8"
      },
      "source": [
        "plt.figure(figsize=[8,6])\n",
        "\n",
        "plt.plot(resnet_history.history['acc'],'r',linewidth=3.0)\n",
        "\n",
        "plt.plot(resnet_history.history['val_acc'],'b',linewidth=3.0)\n",
        "\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2rxKd6I0VsQ"
      },
      "source": [
        "plt.figure(figsize=[8,6])\n",
        "\n",
        "plt.plot(resnet_history.history['precision'],'r',linewidth=3.0)\n",
        "\n",
        "plt.plot(resnet_history.history['val_precision'],'b',linewidth=3.0)\n",
        "\n",
        "plt.legend(['Training Precision', 'Validation Precision'],fontsize=18)\n",
        "\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Precision',fontsize=16)\n",
        "\n",
        "plt.title('Precision Curves',fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggL3YLv40ziR"
      },
      "source": [
        "plt.figure(figsize=[8,6])\n",
        "\n",
        "plt.plot(resnet_history.history['recall'],'r',linewidth=3.0)\n",
        "\n",
        "plt.plot(resnet_history.history['val_recall'],'b',linewidth=3.0)\n",
        "\n",
        "plt.legend(['Training Recall', 'Validation Recall'],fontsize=18)\n",
        "\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Recall',fontsize=16)\n",
        "\n",
        "plt.title('Recall Curves',fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdpKZ6ZSHqpp"
      },
      "source": [
        "model_save_file = \"TTV2_ResNet_10-6-DO-0-3-lr-001.hdf5\"\n",
        "base_model.save(model_save_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta9jbO5HL5VC"
      },
      "source": [
        "!mv TTV2_ResNet_10-6-DO-0-3-lr-001.hdf5 drive/MyDrive/melenoma_drive_data/saving_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSepggYE5W37"
      },
      "source": [
        "# file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-DBRnDKTySG"
      },
      "source": [
        "!mv ResNet50_finetune-17-00-14 drive/MyDrive/melenoma_drive_data/saving_models_folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmctBUyTyMf"
      },
      "source": [
        "Y_pred = base_model.predict_generator(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPTp2hONb9Ju"
      },
      "source": [
        "resnet_history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87i6aFZiL5hQ"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/melenoma_drive_data/saving_models/TTV2_ResNet_10-1.hdf5')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}